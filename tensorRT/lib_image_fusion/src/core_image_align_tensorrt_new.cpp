#include "core_image_align_tensorrt.h"
#include <fstream>
#include <iostream>
#include <algorithm>
#include <cmath>
#include <NvInfer.h>
#include <cuda_runtime_api.h>

// TensorRT Logger
class Logger : public nvinfer1::ILogger {
    void log(Severity severity, const char* msg) noexcept override {
        if (severity <= Severity::kWARNING)
            std::cout << "[TensorRT] " << msg << std::endl;
    }
} gLogger;

using namespace core;
using namespace std;

std::shared_ptr<ImageAlignTensorRT> ImageAlignTensorRT::create_instance(const Param& param) {
    return std::shared_ptr<ImageAlignTensorRT>(new ImageAlignTensorRT(param));
}

ImageAlignTensorRT::ImageAlignTensorRT(const Param& param) : param_(param) {
    if (!loadEngine(param.engine_path)) {
        throw std::runtime_error("Failed to load TensorRT engine: " + param.engine_path);
    }
    std::cout << "âœ… [TensorRT] Successfully loaded TensorRT engine from: " << param.engine_path << std::endl;
}

ImageAlignTensorRT::~ImageAlignTensorRT() {
    // TensorRT 8.6+ ä½¿ç”¨æ™ºèƒ½æŒ‡é‡ï¼Œä¸éœ€è¦æ‰‹å‹• destroy
    if (context_) {
        delete context_;
        context_ = nullptr;
    }
    if (engine_) {
        delete engine_;
        engine_ = nullptr;
    }
    if (runtime_) {
        delete runtime_;
        runtime_ = nullptr;
    }
}

bool ImageAlignTensorRT::loadEngine(const std::string& engine_path) {
    std::cout << "ğŸ”§ [TensorRT] Loading TensorRT engine: " << engine_path << std::endl;
    
    // æª¢æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    std::ifstream file(engine_path, std::ios::binary);
    if (!file) {
        std::cerr << "âŒ [TensorRT] Engine file not found: " << engine_path << std::endl;
        return false;
    }
    
    // è®€å–å¼•æ“æ–‡ä»¶
    file.seekg(0, file.end);
    size_t size = file.tellg();
    file.seekg(0, file.beg);
    std::vector<char> engine_data(size);
    file.read(engine_data.data(), size);
    file.close();
    
    std::cout << "ğŸ“ [TensorRT] Engine file size: " << (size / 1024.0 / 1024.0) << " MB" << std::endl;
    
    // å‰µå»º TensorRT runtime å’Œ engine
    runtime_ = nvinfer1::createInferRuntime(gLogger);
    if (!runtime_) {
        std::cerr << "âŒ [TensorRT] Failed to create runtime" << std::endl;
        return false;
    }
    
    engine_ = runtime_->deserializeCudaEngine(engine_data.data(), size);
    if (!engine_) {
        std::cerr << "âŒ [TensorRT] Failed to deserialize engine" << std::endl;
        return false;
    }
    
    context_ = engine_->createExecutionContext();
    if (!context_) {
        std::cerr << "âŒ [TensorRT] Failed to create execution context" << std::endl;
        return false;
    }
    
    // é¡¯ç¤ºå¼•æ“ä¿¡æ¯
    int num_bindings = engine_->getNbBindings();
    std::cout << "ğŸ“Š [TensorRT] Engine loaded successfully!" << std::endl;
    std::cout << "ğŸ“Š [TensorRT] Number of bindings: " << num_bindings << std::endl;
    
    // é¡¯ç¤ºè¼¸å…¥è¼¸å‡ºç¶å®šä¿¡æ¯
    for (int i = 0; i < num_bindings; i++) {
        const char* name = engine_->getBindingName(i);
        auto dims = engine_->getBindingDimensions(i);
        bool is_input = engine_->bindingIsInput(i);
        
        std::cout << "  " << (is_input ? "ğŸ“¥" : "ğŸ“¤") << " " 
                  << (is_input ? "Input" : "Output") << " " << i 
                  << ": " << name << " | Shape: (";
        
        for (int j = 0; j < dims.nbDims; j++) {
            std::cout << dims.d[j];
            if (j < dims.nbDims - 1) std::cout << ", ";
        }
        std::cout << ")" << std::endl;
    }
    
    return true;
}

void ImageAlignTensorRT::align(const cv::Mat& eo, const cv::Mat& ir, std::vector<cv::Point2i>& eo_pts, std::vector<cv::Point2i>& ir_pts, cv::Mat& H) {
    try {
        std::cout << "ğŸ” [TensorRT] ===== Starting TensorRT Alignment =====" << std::endl;
        
        // é æ¸¬ç‰¹å¾µé» (åŸºæ–¼ test_trt_inference.py çš„æˆåŠŸå¯¦ä½œ)
        pred(eo, ir, eo_pts, ir_pts);
        
        std::cout << "ğŸ¯ [TensorRT] å…±æœ‰ " << eo_pts.size() << " å€‹ EO ç‰¹å¾µé», " << ir_pts.size() << " å€‹ IR ç‰¹å¾µé»" << std::endl;
        
        // è¨ˆç®— homography
        if (eo_pts.size() >= 4 && ir_pts.size() >= 4) {
            // è½‰æ›ç‚º Point2f é€²è¡Œ homography è¨ˆç®—
            std::vector<cv::Point2f> eo_pts_f, ir_pts_f;
            for (const auto& pt : eo_pts) {
                eo_pts_f.emplace_back(pt.x, pt.y);
            }
            for (const auto& pt : ir_pts) {
                ir_pts_f.emplace_back(pt.x, pt.y);
            }
            
            // ä½¿ç”¨ RANSAC è¨ˆç®— homography
            cv::Mat mask;
            H = cv::findHomography(eo_pts_f, ir_pts_f, cv::RANSAC, 8.0, mask, 800, 0.98);
            
            if (!H.empty() && cv::determinant(H) > 1e-6) {
                std::cout << "âœ… [TensorRT] Successfully computed homography matrix" << std::endl;
                
                // æ ¹æ“š homography éæ¿¾ç‰¹å¾µé»
                std::vector<cv::Point2i> filtered_eo_pts, filtered_ir_pts;
                for (size_t i = 0; i < eo_pts.size() && i < mask.rows; i++) {
                    if (mask.at<uchar>(i, 0) > 0) {
                        filtered_eo_pts.push_back(eo_pts[i]);
                        filtered_ir_pts.push_back(ir_pts[i]);
                    }
                }
                
                std::cout << "ğŸ” [TensorRT] RANSAC å¾Œæœ‰æ•ˆç‰¹å¾µé»å°: " << filtered_eo_pts.size() << std::endl;
                
                eo_pts = filtered_eo_pts;
                ir_pts = filtered_ir_pts;
            } else {
                std::cout << "âŒ [TensorRT] Failed to compute valid homography" << std::endl;
                H = cv::Mat::eye(3, 3, CV_64F);
            }
        } else {
            std::cout << "âš ï¸ [TensorRT] Insufficient points for homography calculation (" << eo_pts.size() << " points)" << std::endl;
            H = cv::Mat::eye(3, 3, CV_64F);
        }
        
        std::cout << "âœ… [TensorRT] ===== TensorRT Alignment Complete =====" << std::endl;
        
    } catch (const std::exception& e) {
        std::cerr << "âŒ [TensorRT] Error in alignment: " << e.what() << std::endl;
        H = cv::Mat::eye(3, 3, CV_64F);
    }
}

void ImageAlignTensorRT::pred(const cv::Mat& eo, const cv::Mat& ir, std::vector<cv::Point2i>& eo_pts, std::vector<cv::Point2i>& ir_pts) {
    std::cout << "ğŸ” [TensorRT] Starting inference..." << std::endl;
    
    if (eo.channels() != 1 || ir.channels() != 1) {
        throw std::runtime_error("[TensorRT] eo and ir must be single channel images");
    }
    
    // Resize input images to pred_width x pred_height
    cv::Mat eo_temp, ir_temp;
    cv::resize(eo, eo_temp, cv::Size(param_.input_w, param_.input_h));
    cv::resize(ir, ir_temp, cv::Size(param_.input_w, param_.input_h));
    
    std::cout << "ğŸ“Š [TensorRT] Input images resized to: " << param_.input_w << "x" << param_.input_h << std::endl;
    
    // æ­£è¦åŒ–åˆ° [0,1]
    eo_temp.convertTo(eo_temp, CV_32F, 1.0f / 255.0f);
    ir_temp.convertTo(ir_temp, CV_32F, 1.0f / 255.0f);
    
    // ç¢ºä¿è¨˜æ†¶é«”é€£çºŒæ€§
    eo_temp = eo_temp.clone();
    ir_temp = ir_temp.clone();
    
    std::cout << "ğŸ“Š [TensorRT] Images normalized, range: [0, 1]" << std::endl;
    std::cout << "ğŸ“Š [TensorRT] EO image range: [" << eo_temp.ptr<float>()[0] << ", " 
              << *std::max_element(eo_temp.ptr<float>(), eo_temp.ptr<float>() + eo_temp.total()) << "]" << std::endl;
    
    // æ¸…ç©ºè¼¸å‡º
    eo_pts.clear();
    ir_pts.clear();
    
    // é‹è¡Œ TensorRT æ¨è«–
    if (!runInference(eo_temp, ir_temp, eo_pts, ir_pts)) {
        std::cerr << "âŒ [TensorRT] Inference failed!" << std::endl;
        // ä¸ä½¿ç”¨ fallbackï¼Œè®“éŒ¯èª¤æ˜ç¢ºé¡¯ç¤º
        return;
    }
    
    std::cout << "âœ… [TensorRT] Inference completed successfully!" << std::endl;
}

bool ImageAlignTensorRT::runInference(const cv::Mat& eo_img, const cv::Mat& ir_img, 
                                      std::vector<cv::Point2i>& eo_pts, std::vector<cv::Point2i>& ir_pts) {
    
    std::cout << "âš¡ [TensorRT] Executing inference..." << std::endl;
    
    // ç²å–ç¶å®šä¿¡æ¯
    int num_bindings = engine_->getNbBindings();
    std::vector<void*> buffers(num_bindings);
    
    // è¨­ç½®è¼¸å…¥
    int input_idx_vi = 0; // å‡è¨­ç¬¬ä¸€å€‹è¼¸å…¥æ˜¯å¯è¦‹å…‰
    int input_idx_ir = 1; // å‡è¨­ç¬¬äºŒå€‹è¼¸å…¥æ˜¯ç´…å¤–ç·š
    
    // ç‚ºè¼¸å…¥åˆ†é… GPU è¨˜æ†¶é«”ä¸¦è¤‡è£½æ•¸æ“š
    size_t input_size = eo_img.total() * sizeof(float);
    
    void* d_input_vi;
    void* d_input_ir;
    cudaMalloc(&d_input_vi, input_size);
    cudaMalloc(&d_input_ir, input_size);
    
    // è¤‡è£½æ•¸æ“šåˆ° GPUï¼Œæ³¨æ„ OpenCV Mat å¯èƒ½ä¸æ˜¯é€£çºŒçš„
    cv::Mat eo_continuous = eo_img.isContinuous() ? eo_img : eo_img.clone();
    cv::Mat ir_continuous = ir_img.isContinuous() ? ir_img : ir_img.clone();
    
    cudaMemcpy(d_input_vi, eo_continuous.ptr<float>(), input_size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_input_ir, ir_continuous.ptr<float>(), input_size, cudaMemcpyHostToDevice);
    
    buffers[input_idx_vi] = d_input_vi;
    buffers[input_idx_ir] = d_input_ir;
    
    // ç‚ºè¼¸å‡ºåˆ†é…è¨˜æ†¶é«”
    std::vector<void*> d_outputs;
    std::vector<size_t> output_sizes;
    
    for (int i = 0; i < num_bindings; i++) {
        if (!engine_->bindingIsInput(i)) {
            auto dims = engine_->getBindingDimensions(i);
            
            size_t output_size = 1;
            for (int j = 0; j < dims.nbDims; j++) {
                output_size *= dims.d[j];
            }
            output_size *= sizeof(float); // å‡è¨­è¼¸å‡ºæ˜¯ float
            
            void* d_output;
            cudaMalloc(&d_output, output_size);
            d_outputs.push_back(d_output);
            output_sizes.push_back(output_size);
            buffers[i] = d_output;
            
            std::cout << "ğŸ“¤ [TensorRT] Output " << i << " allocated: " 
                      << (output_size / sizeof(float)) << " elements" << std::endl;
        }
    }
    
    // åŸ·è¡Œæ¨è«–
    cudaStream_t stream;
    cudaStreamCreate(&stream);
    
    bool success = context_->executeV2(buffers.data());
    
    if (!success) {
        std::cerr << "âŒ [TensorRT] Engine execution failed" << std::endl;
        cudaStreamDestroy(stream);
        cudaFree(d_input_vi);
        cudaFree(d_input_ir);
        for (void* d_output : d_outputs) {
            cudaFree(d_output);
        }
        return false;
    }
    
    std::cout << "âš¡ [TensorRT] Engine execution successful!" << std::endl;
    
    // è¤‡è£½è¼¸å‡ºå› CPU ä¸¦è§£æç‰¹å¾µé»
    // å‡è¨­è¼¸å‡ºé †åº: leng1, mkpt0, leng2, mkpt1 (åŸºæ–¼ Python ç‰ˆæœ¬)
    if (d_outputs.size() >= 4) {
        // è¤‡è£½ leng1 (æœ‰æ•ˆ EO ç‰¹å¾µé»æ•¸é‡)
        int leng1;
        cudaMemcpy(&leng1, d_outputs[0], sizeof(int), cudaMemcpyDeviceToHost);
        
        // è¤‡è£½ mkpt0 (EO ç‰¹å¾µé»ï¼Œå‡è¨­æœ€å¤§ 1200 å€‹)
        std::vector<float> mkpt0_data(1200 * 2); // 1200 points * (x,y)
        cudaMemcpy(mkpt0_data.data(), d_outputs[1], output_sizes[1], cudaMemcpyDeviceToHost);
        
        // è¤‡è£½ leng2 (æœ‰æ•ˆ IR ç‰¹å¾µé»æ•¸é‡)
        int leng2;
        cudaMemcpy(&leng2, d_outputs[2], sizeof(int), cudaMemcpyDeviceToHost);
        
        // è¤‡è£½ mkpt1 (IR ç‰¹å¾µé»)
        std::vector<float> mkpt1_data(1200 * 2); // 1200 points * (x,y)
        cudaMemcpy(mkpt1_data.data(), d_outputs[3], output_sizes[3], cudaMemcpyDeviceToHost);
        
        std::cout << "ğŸ¯ [TensorRT] leng1 (æœ‰æ•ˆ EO ç‰¹å¾µé»): " << leng1 << std::endl;
        std::cout << "ğŸ¯ [TensorRT] leng2 (æœ‰æ•ˆ IR ç‰¹å¾µé»): " << leng2 << std::endl;
        
        // æå–æœ‰æ•ˆç‰¹å¾µé» (åªå–å‰ leng1/leng2 å€‹ï¼Œéæ¿¾ (0,0) é»)
        for (int i = 0; i < std::min(leng1, 1200); i++) {
            float x = mkpt0_data[i * 2];
            float y = mkpt0_data[i * 2 + 1];
            if (x != 0.0f || y != 0.0f) { // éæ¿¾ (0,0) å¡«å……é»
                eo_pts.push_back(cv::Point2i(static_cast<int>(x), static_cast<int>(y)));
            }
        }
        
        for (int i = 0; i < std::min(leng2, 1200); i++) {
            float x = mkpt1_data[i * 2];
            float y = mkpt1_data[i * 2 + 1];
            if (x != 0.0f || y != 0.0f) { // éæ¿¾ (0,0) å¡«å……é»
                ir_pts.push_back(cv::Point2i(static_cast<int>(x), static_cast<int>(y)));
            }
        }
        
        std::cout << "âœ… [TensorRT] æå–åˆ° " << eo_pts.size() << " å€‹æœ‰æ•ˆ EO ç‰¹å¾µé»" << std::endl;
        std::cout << "âœ… [TensorRT] æå–åˆ° " << ir_pts.size() << " å€‹æœ‰æ•ˆ IR ç‰¹å¾µé»" << std::endl;
        
        // é¡¯ç¤ºç‰¹å¾µé»ç¯„åœ
        if (!eo_pts.empty()) {
            int min_x = std::min_element(eo_pts.begin(), eo_pts.end(), 
                                       [](const cv::Point2i& a, const cv::Point2i& b) { return a.x < b.x; })->x;
            int max_x = std::max_element(eo_pts.begin(), eo_pts.end(), 
                                       [](const cv::Point2i& a, const cv::Point2i& b) { return a.x < b.x; })->x;
            int min_y = std::min_element(eo_pts.begin(), eo_pts.end(), 
                                       [](const cv::Point2i& a, const cv::Point2i& b) { return a.y < b.y; })->y;
            int max_y = std::max_element(eo_pts.begin(), eo_pts.end(), 
                                       [](const cv::Point2i& a, const cv::Point2i& b) { return a.y < b.y; })->y;
            
            std::cout << "ğŸ“Š [TensorRT] EO ç‰¹å¾µé»ç¯„åœ: x[" << min_x << ", " << max_x << "], y[" << min_y << ", " << max_y << "]" << std::endl;
        }
        
    } else {
        std::cerr << "âŒ [TensorRT] Expected 4 outputs, got " << d_outputs.size() << std::endl;
    }
    
    // æ¸…ç†è¨˜æ†¶é«”
    cudaStreamDestroy(stream);
    cudaFree(d_input_vi);
    cudaFree(d_input_ir);
    for (void* d_output : d_outputs) {
        cudaFree(d_output);
    }
    
    return true;
}
