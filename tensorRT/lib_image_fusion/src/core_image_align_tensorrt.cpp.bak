#include "core_image_align_tensorrt.h"
#include <fstream>
#include <iostream>
#include <algorithm>
#include <cmath>
#include <NvInfer.h>
#include <cuda_runtime_api.h>

// TensorRT Logger
class Logger : public nvinfer1::ILogger {
    void log(Severity severity, const char* msg) noexcept override {
        if (severity <= Severity::kWARNING)
            std::cout << "[TensorRT] " << msg << std::endl;
    }
} gLogger;

using namespace core;
using namespace std;

std::shared_ptr<ImageAlignTensorRT> ImageAlignTensorRT::create_instance(const Param& param) {
    return std::shared_ptr<ImageAlignTensorRT>(new ImageAlignTensorRT(param));
}

ImageAlignTensorRT::ImageAlignTensorRT(const Param& param) : param_(param) {
    if (!loadEngine(param.engine_path)) {
        throw std::runtime_error("Failed to load TensorRT engine: " + param.engine_path);
    }
    std::cout << "Successfully loaded TensorRT engine from: " << param.engine_path << std::endl;
}

ImageAlignTensorRT::~ImageAlignTensorRT() {
    // TensorRT 8.6+ 使用智能指針，不需要手動 destroy
    if (context_) {
        delete context_;
        context_ = nullptr;
    }
    if (engine_) {
        delete engine_;
        engine_ = nullptr;
    }
    if (runtime_) {
        delete runtime_;
        runtime_ = nullptr;
    }
}

bool ImageAlignTensorRT::loadEngine(const std::string& engine_path) {
    // 檢查模型文件是否存在
    std::ifstream file(engine_path, std::ios::binary);
    if (!file) {
        std::cerr << "[TensorRT] Engine file not found: " << engine_path << std::endl;
        return false;
    }
    
    // 讀取引擎文件
    file.seekg(0, file.end);
    size_t size = file.tellg();
    file.seekg(0, file.beg);
    std::vector<char> engine_data(size);
    file.read(engine_data.data(), size);
    file.close();
    
    // 創建 TensorRT runtime 和 engine
    runtime_ = nvinfer1::createInferRuntime(gLogger);
    if (!runtime_) {
        std::cerr << "[TensorRT] Failed to create runtime" << std::endl;
        return false;
    }
    
    engine_ = runtime_->deserializeCudaEngine(engine_data.data(), size);
    if (!engine_) {
        std::cerr << "[TensorRT] Failed to deserialize engine" << std::endl;
        return false;
    }
    
    context_ = engine_->createExecutionContext();
    if (!context_) {
        std::cerr << "[TensorRT] Failed to create execution context" << std::endl;
        return false;
    }
    
    std::cout << "[TensorRT] Engine loaded successfully, input/output binding count: " << engine_->getNbBindings() << std::endl;
    return true;
}

void ImageAlignTensorRT::align(const cv::Mat& eo, const cv::Mat& ir, std::vector<cv::Point2i>& eo_pts, std::vector<cv::Point2i>& ir_pts, cv::Mat& H) {
    try {
        std::cout<<'***************************************************************'<<endl;
        // 預測特徵點 (模仿 onnx.cpp 的 pred 函數)
        pred(eo, ir, eo_pts, ir_pts);
        
        // 計算 homography (完全複製 onnx.cpp 的邏輯)
        if (eo_pts.size() >= 4 && ir_pts.size() >= 4) {
            // 轉換為 Point2f 進行 homography 計算
            std::vector<cv::Point2f> eo_pts_f, ir_pts_f;
            for (const auto& pt : eo_pts) {
                eo_pts_f.emplace_back(pt.x, pt.y);
            }
            for (const auto& pt : ir_pts) {
                ir_pts_f.emplace_back(pt.x, pt.y);
            }
            
            // 使用 RANSAC 計算 homography
            cv::Mat mask;
            H = cv::findHomography(eo_pts_f, ir_pts_f, cv::RANSAC, 8.0, mask, 800, 0.98);
            
            if (!H.empty() && cv::determinant(H) > 1e-6) {
                std::cout << "[TensorRT] Successfully computed homography matrix" << std::endl;
                
                // 根據 homography 過濾特徵點
                std::vector<cv::Point2i> filtered_eo_pts, filtered_ir_pts;
                for (size_t i = 0; i < eo_pts.size(); i++) {
                    if (i < mask.rows && mask.at<uchar>(i, 0) > 0) {
                        filtered_eo_pts.push_back(eo_pts[i]);
                        filtered_ir_pts.push_back(ir_pts[i]);
                    }
                }
                eo_pts = filtered_eo_pts;
                ir_pts = filtered_ir_pts;
            } else {
                std::cout << "[TensorRT] Failed to compute valid homography" << std::endl;
                H = cv::Mat::eye(3, 3, CV_64F);
            }
        } else {
            std::cout << "[TensorRT] Insufficient points for homography calculation (" << eo_pts.size() << " points)" << std::endl;
            H = cv::Mat::eye(3, 3, CV_64F);
        }
    } catch (const std::exception& e) {
        std::cerr << "[TensorRT] Error in alignment: " << e.what() << std::endl;
        H = cv::Mat::eye(3, 3, CV_64F);
    }
}

void ImageAlignTensorRT::pred(const cv::Mat& eo, const cv::Mat& ir, std::vector<cv::Point2i>& eo_pts, std::vector<cv::Point2i>& ir_pts) {
    if (eo.channels() != 1 || ir.channels() != 1) {
        throw std::runtime_error("[TensorRT] eo and ir must be single channel images");
    }
    
    // resize input image to pred_width x pred_height (複製 onnx.cpp 邏輯)
    cv::Mat eo_temp, ir_temp;
    cv::resize(eo, eo_temp, cv::Size(param_.input_w, param_.input_h));
    cv::resize(ir, ir_temp, cv::Size(param_.input_w, param_.input_h));
    
    // 正規化到 [0,1] (複製 onnx.cpp 邏輯)
    eo_temp.convertTo(eo_temp, CV_32F, 1.0f / 255.0f);
    ir_temp.convertTo(ir_temp, CV_32F, 1.0f / 255.0f);
    
    // 確保記憶體連續性
    eo_temp = eo_temp.clone();
    ir_temp = ir_temp.clone();
    
    // 清空輸出
    eo_pts.clear();
    ir_pts.clear();
    
    // 準備 TensorRT 輸入數據
    if (!runInference(eo_temp, ir_temp, eo_pts, ir_pts)) {
        std::cerr << "[TensorRT] Inference failed, falling back to dummy data" << std::endl;
        
        // 生成一些假的特徵點以測試流程 (fallback)
        for (int i = 0; i < 10; i++) {
            int x = 50 + i * 20;
            int y = 50 + i * 15;
            eo_pts.push_back(cv::Point2i(x, y));
            ir_pts.push_back(cv::Point2i(x + 5, y + 3)); // 稍微偏移
        }
        std::cout << "[TensorRT] Generated " << eo_pts.size() << " fallback feature point pairs" << std::endl;
    }
}
